{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import ADASYN \n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB \n",
    "from sklearn import metrics\n",
    "from pylab import rcParams\n",
    "\n",
    "rcParams['figure.figsize'] = 14, 8\n",
    "RANDOM_SEED = 42\n",
    "LABELS = [\"Normal\", \"Fraud\"]\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.offline import init_notebook_mode, iplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:\\\\Users\\\\Dell\\\\Desktop\\\\creditcard.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 284807 rows and 31 columns.\n"
     ]
    }
   ],
   "source": [
    "print('The dataset contains {0} rows and {1} columns.'.format(data.shape[0], data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal transactions count:  284315\n",
      "Fraudulent transactions count:  492\n"
     ]
    }
   ],
   "source": [
    "print('Normal transactions count: ', data['Class'].value_counts().values[0])\n",
    "print('Fraudulent transactions count: ', data['Class'].value_counts().values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature data (predictors)\n",
    "X = data.iloc[:, :-1]\n",
    "\n",
    "# label class\n",
    "y = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data to have zero mean and unit variance.\n",
    "scaler = StandardScaler()\n",
    "scaled_X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 190477, 1: 343})\n",
      "Resampled dataset shape Counter({0: 190477, 1: 190471})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# apply the ADASYN over-sampling\n",
    "ada = ADASYN(random_state=42)\n",
    "print('Original dataset shape {}'.format(Counter(y_train)))\n",
    "X_res, y_res = ada.fit_sample(X_train, y_train)\n",
    "print('Resampled dataset shape {}'.format(Counter(y_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning:\n",
      "\n",
      "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = X_res, y_res \n",
    "# Train LogisticRegression Model\n",
    "\n",
    "LGR_Classifier = LogisticRegression()\n",
    "LGR_Classifier.fit(X_train, y_train);\n",
    "\n",
    "# Train Bernoulli Naive Baye Model\n",
    "BNB_Classifier = BernoulliNB()\n",
    "BNB_Classifier.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================== Model Evaluation Results ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning:\n",
      "\n",
      "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning:\n",
      "\n",
      "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning:\n",
      "\n",
      "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning:\n",
      "\n",
      "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning:\n",
      "\n",
      "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning:\n",
      "\n",
      "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning:\n",
      "\n",
      "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning:\n",
      "\n",
      "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning:\n",
      "\n",
      "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning:\n",
      "\n",
      "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== LogisticRegression =====\n",
      "\n",
      "Cross Validation Mean Score:  87.4%\n",
      "\n",
      "Model Accuracy:  90.10000000000001%\n",
      "\n",
      "Confusion Matrix:\n",
      " [[174053  16424]\n",
      " [ 21296 169175]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90    190477\n",
      "           1       0.91      0.89      0.90    190471\n",
      "\n",
      "   micro avg       0.90      0.90      0.90    380948\n",
      "   macro avg       0.90      0.90      0.90    380948\n",
      "weighted avg       0.90      0.90      0.90    380948\n",
      "\n",
      "\n",
      "===== Naive Baiye Classifier =====\n",
      "\n",
      "Cross Validation Mean Score:  83.6%\n",
      "\n",
      "Model Accuracy:  84.7%\n",
      "\n",
      "Confusion Matrix:\n",
      " [[170272  20205]\n",
      " [ 38005 152466]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85    190477\n",
      "           1       0.88      0.80      0.84    190471\n",
      "\n",
      "   micro avg       0.85      0.85      0.85    380948\n",
      "   macro avg       0.85      0.85      0.85    380948\n",
      "weighted avg       0.85      0.85      0.85    380948\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models\n",
    "modlist = [('LogisticRegression', LGR_Classifier),\n",
    "('Naive Baiye Classifier', BNB_Classifier)] \n",
    "\n",
    "models = [j for j in modlist]\n",
    "\n",
    "print()\n",
    "print('========================== Model Evaluation Results ========================' \"\\n\")  \n",
    "\n",
    "for i, v in models:\n",
    "    scores = cross_val_score(v, X_train, y_train, cv=10)\n",
    "    accuracy = metrics.accuracy_score(y_train, v.predict(X_train))\n",
    "    confusion_matrix = metrics.confusion_matrix(y_train, v.predict(X_train))\n",
    "    classification = metrics.classification_report(y_train, v.predict(X_train))\n",
    "    print('===== {} ====='.format(i))\n",
    "    print()\n",
    "    print (\"Cross Validation Mean Score: \", '{}%'.format(np.round(scores.mean(), 3) * 100))  \n",
    "    print() \n",
    "    print (\"Model Accuracy: \", '{}%'.format(np.round(accuracy, 3) * 100)) \n",
    "    print()\n",
    "    print(\"Confusion Matrix:\" \"\\n\", confusion_matrix)\n",
    "    print()\n",
    "    print(\"Classification Report:\" \"\\n\", classification) \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================== Model Test Results ========================\n",
      "\n",
      "=== LogisticRegression ===\n",
      "Model Accuracy:  91.2%\n",
      "\n",
      "Confusion Matrix:\n",
      " [[85582  8256]\n",
      " [    7   142]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95     93838\n",
      "           1       0.02      0.95      0.03       149\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     93987\n",
      "   macro avg       0.51      0.93      0.49     93987\n",
      "weighted avg       1.00      0.91      0.95     93987\n",
      "\n",
      "\n",
      "=== Naive Baiye Classifier ===\n",
      "Model Accuracy:  89.4%\n",
      "\n",
      "Confusion Matrix:\n",
      " [[83840  9998]\n",
      " [   10   139]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94     93838\n",
      "           1       0.01      0.93      0.03       149\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     93987\n",
      "   macro avg       0.51      0.91      0.49     93987\n",
      "weighted avg       1.00      0.89      0.94     93987\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test models\n",
    "classdict = {'normal':0, 'fraudulent':1}\n",
    "print()\n",
    "print('========================== Model Test Results ========================' \"\\n\")   \n",
    "\n",
    "for i, v in models:\n",
    "    accuracy = metrics.accuracy_score(y_test, v.predict(X_test))\n",
    "    confusion_matrix = metrics.confusion_matrix(y_test, v.predict(X_test))\n",
    "    classification = metrics.classification_report(y_test, v.predict(X_test))   \n",
    "    print('=== {} ==='.format(i))\n",
    "    print (\"Model Accuracy: \",  '{}%'.format(np.round(accuracy, 3) * 100))\n",
    "    print()\n",
    "    print(\"Confusion Matrix:\" \"\\n\", confusion_matrix)\n",
    "    print()\n",
    " #   pf.plot_confusion_matrix(confusion_matrix, classes = list(classdict.keys()), title='Confusion Matrix Plot', cmap=plt.cm.summer)\n",
    "    print() \n",
    "    print(\"Classification Report:\" \"\\n\", classification) \n",
    "    print() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
